{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HAP Transform Example Notebook\n",
    "=====================================\n",
    "This notebook picks a CSV file from the `input` folder, converts it to Parquet format,\n",
    "runs the `hap_local_python.py` transform, and displays the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Overview\n",
    "This notebook demonstrates the use of the HAP transformation to annotate documents with a `hap_score`, \n",
    "indicating the likelihood of Hate, Abuse, or Profanity in the text.\n",
    "\n",
    "### Workflow\n",
    "The HAP process consists of:\n",
    "1. **Sentence Splitting**: Documents are split into sentences using NLTK.\n",
    "2. **HAP Annotation**: Each sentence is scored between 0 and 1 (1 = high HAP, 0 = no HAP).\n",
    "3. **Aggregation**: The document's final HAP score is the maximum score among all sentences.\n",
    "\n",
    "\n",
    "### Configuration\n",
    "- **Model Name**: IBM Granite Guardian (`ibm-granite/granite-guardian-hap-38m` by default).\n",
    "- **Document Text Column** (`--doc_text_column`): Specify the input column containing document text to generate the hap_score against. Defaults to `contents`.\n",
    "- **Annotation Column** (`--annotation_column`): Specify the output column for HAP scores. Defaults to `hap_score`.\n",
    "\n",
    "\n",
    "### Steps in This Notebook\n",
    "1. Define paths and import libraries.\n",
    "2. Convert CSV input to Parquet.\n",
    "3. Run the HAP transformation script.\n",
    "4. View and analyze the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Paths\n",
    "---------------------\n",
    "Define the paths for the script, input folder, and output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_script_path = \"./transforms/universal/hap/python/src/hap_local_python.py\"\n",
    "input_folder = \"./input\"\n",
    "output_folder = \"./output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Path: ./transforms/universal/hap/python/src/hap_local_python.py\n",
      "Input Folder: ./input\n",
      "Output Folder: ./output\n"
     ]
    }
   ],
   "source": [
    "# Ensure the necessary folders exist.\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "print(f\"Script Path: {hap_script_path}\")\n",
    "print(f\"Input Folder: {input_folder}\")\n",
    "print(f\"Output Folder: {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Check for CSV Files in Input Folder\n",
    "\n",
    "- Place your CSV file in the `input_folder`.\n",
    "- Ensure the column containing the text matches the `doc_text_column` parameter.\n",
    "- If your text column has a different name, update the `doc_text_column` parameter in later cells.\n",
    "- This cell sets up the file paths for the input file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file(s): ['customer_feedback_file.csv']\n",
      "Using CSV file: ./input/customer_feedback_file.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "if not csv_files:\n",
    "    print(f\"No CSV files found in the input folder: {input_folder}\")\n",
    "    print(\"Please place a CSV file in the input folder and rerun this notebook.\")\n",
    "else:\n",
    "    print(f\"Found CSV file(s): {csv_files}\")\n",
    "\n",
    "# Pick the first CSV file in the folder\n",
    "csv_file_path = os.path.join(input_folder, csv_files[0])\n",
    "print(f\"Using CSV file: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Convert CSV to Parquet\n",
    "Convert the selected CSV file to Parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file converted to Parquet format at: ./input/data.parquet\n"
     ]
    }
   ],
   "source": [
    "parquet_file_path = os.path.join(input_folder, \"data.parquet\")\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df.to_parquet(parquet_file_path, index=False)\n",
    "print(f\"CSV file converted to Parquet format at: {parquet_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Simulate Command-Line Arguments for HAP Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command-line arguments: ['hap_local_python.py', '--input_folder', './input', '--output_folder', './output', '--model_name_or_path', 'ibm-granite/granite-guardian-hap-38m', '--annotation_column', 'hap_score', '--doc_text_column', 'Customer Feedback', '--inference_engine', 'CPU', '--max_length', '512', '--batch_size', '128']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clear sys.argv first to avoid conflicts (reset arguments list)\n",
    "sys.argv = [\n",
    "    \"hap_local_python.py\",             # Script name\n",
    "    \"--input_folder\", input_folder,    # Correct input folder\n",
    "    \"--output_folder\", output_folder,  # Correct output folder\n",
    "    \"--model_name_or_path\", hap_params[\"model_name_or_path\"],\n",
    "    \"--annotation_column\", hap_params[\"annotation_column\"],\n",
    "    \"--doc_text_column\", hap_params[\"doc_text_column\"],\n",
    "    \"--inference_engine\", hap_params[\"inference_engine\"],\n",
    "    \"--max_length\", str(hap_params[\"max_length\"]),\n",
    "    \"--batch_size\", str(hap_params[\"batch_size\"]),\n",
    "]\n",
    "\n",
    "print(f\"Command-line arguments: {sys.argv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run the Transform with Simulated Arguments\n",
    "\n",
    "This cell executes the HAP transformation script:\n",
    "- `--input_file`: Path to your input CSV/Parquet file.\n",
    "- `--output_file`: Path where the output file with HAP scores will be saved.\n",
    "- `--doc_text_column`: The column containing the text for analysis (default: `Customer Feedback`).\n",
    "- `--annotation_column`: The column where HAP scores will be saved (default: `hap_score`).\n",
    "\n",
    "**Customization**: \n",
    "- If your text column has a different name, update the value of `--doc_text_column` accordingly.\n",
    "- You can adjust other parameters like `--batch_size` and `--max_length` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred during transform execution.\n",
      "python: can't open file '/Users/aisha/Documents/GitHub/Personal/DPK/examples/notebooks/hap/./transforms/universal/hap/python/src/hap_local_python.py': [Errno 2] No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copy the current environment variables\n",
    "env = os.environ.copy()\n",
    "\n",
    "# Set Environment Variables for HAP Parameters\n",
    "os.environ[\"MODEL_NAME_OR_PATH\"] = \"ibm-granite/granite-guardian-hap-38m\"\n",
    "os.environ[\"ANNOTATION_COLUMN\"] = \"hap_score\"\n",
    "os.environ[\"DOC_TEXT_COLUMN\"] = \"Customer Feedback\"\n",
    "os.environ[\"INFERENCE_ENGINE\"] = \"CPU\"\n",
    "os.environ[\"MAX_LENGTH\"] = \"512\"\n",
    "os.environ[\"BATCH_SIZE\"] = \"128\"\n",
    "os.environ[\"INPUT_FOLDER\"] = input_folder\n",
    "os.environ[\"OUTPUT_FOLDER\"] = output_folder\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"python\", hap_script_path],\n",
    "        check=True,\n",
    "        text=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "\n",
    "    # If successful, print the result of the transform\n",
    "    print(\"Transform completed successfully.\")\n",
    "    print(result.stdout)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # If there was an error, print the error message\n",
    "    print(\"Error occurred during transform execution.\")\n",
    "    print(e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Generate the Output CSV\n",
    "\n",
    "This step checks for any existing CSV files in the output folder and removes them before generating new ones. The following actions are performed:\n",
    "\n",
    "1. **Listing Output Files**: The script lists all files in the output folder.\n",
    "2. **Check for Parquet Files**: It identifies `.parquet` files in the output folder.\n",
    "3. **Remove Old CSV Files**: If any previous output files (`hap_complete_output.csv` or `hap_filtered_output.csv`) exist, they are deleted.\n",
    "4. **Read Parquet File**: The Parquet file is read into a DataFrame.\n",
    "5. **Filter Data**: The relevant columns, `doc_text_column` (from the environment variable) and `hap_score_column`, are selected from the DataFrame.\n",
    "6. **Save New CSV Files**: The filtered data is saved into two new CSV files:\n",
    "   - `hap_complete_output.csv` (containing the full output)\n",
    "   - `hap_filtered_output.csv` (containing only the filtered relevant columns).\n",
    "\n",
    "This ensures that only the latest output is retained, and no old files remain in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Output Parquet File Path: ./output/data.parquet\n",
      "Old complete CSV file removed: ./output/hap_complete_output.csv\n",
      "Old filtered CSV file removed: ./output/hap_filtered_output.csv\n",
      "Filtered Output (only HAP score and document text):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>hap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rating: 4 Comments: \"Service was prompt, but ...</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rating: 5 Comments: \"Great help from Peter! H...</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rating: 3 Comments: \"The service was quick, b...</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rating: 5 Comments: \"Excellent service and ad...</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rating: 2 Comments: \"I’m really frustrated. T...</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Rating: 3 Comments: \"This is not what I expec...</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Rating: 1 Comments: \"This is insane. I’ve onl...</td>\n",
       "      <td>0.579251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Rating: 4 Comments: \"I need this ﬁxed. I can’...</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Rating: 2 Comments: \"I’m so done with this ma...</td>\n",
       "      <td>0.000285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Rating: 3 Comments: \"I’ve leveled the machine...</td>\n",
       "      <td>0.052517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Customer Feedback  hap_score\n",
       "0    Rating: 4 Comments: \"Service was prompt, but ...   0.000195\n",
       "1    Rating: 5 Comments: \"Great help from Peter! H...   0.000153\n",
       "2    Rating: 3 Comments: \"The service was quick, b...   0.000169\n",
       "3    Rating: 5 Comments: \"Excellent service and ad...   0.000158\n",
       "4    Rating: 2 Comments: \"I’m really frustrated. T...   0.000875\n",
       "..                                                ...        ...\n",
       "60   Rating: 3 Comments: \"This is not what I expec...   0.000150\n",
       "61   Rating: 1 Comments: \"This is insane. I’ve onl...   0.579251\n",
       "62   Rating: 4 Comments: \"I need this ﬁxed. I can’...   0.000384\n",
       "63   Rating: 2 Comments: \"I’m so done with this ma...   0.000285\n",
       "64   Rating: 3 Comments: \"I’ve leveled the machine...   0.052517\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete output saved to: ./output/hap_complete_output.csv\n",
      "Filtered output saved to: ./output/hap_filtered_output.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List all files in the output folder\n",
    "output_files = os.listdir(output_folder)\n",
    "\n",
    "if output_files:\n",
    "    for file in output_files:\n",
    "        if file.endswith(\".parquet\"):  # Check for Parquet output files\n",
    "            output_file_path = os.path.join(output_folder, file)\n",
    "            output_df = pd.read_parquet(output_file_path)  # Read the Parquet file\n",
    "            print(f\"Complete Output Parquet File Path: {output_file_path}\")\n",
    "\n",
    "            # Define the output CSV file paths\n",
    "            complete_output_csv = os.path.join(output_folder, \"hap_complete_output.csv\")\n",
    "            filtered_output_csv = os.path.join(output_folder, \"hap_filtered_output.csv\")\n",
    "\n",
    "            # Remove old CSV files if they exist\n",
    "            if os.path.exists(complete_output_csv):\n",
    "                os.remove(complete_output_csv)\n",
    "                print(f\"Old complete CSV file removed: {complete_output_csv}\")\n",
    "\n",
    "            if os.path.exists(filtered_output_csv):\n",
    "                os.remove(filtered_output_csv)\n",
    "                print(f\"Old filtered CSV file removed: {filtered_output_csv}\")\n",
    "\n",
    "            # Filter the output DataFrame to only include the relevant columns\n",
    "            hap_score_column = hap_params[\"annotation_column\"]\n",
    "            doc_text_column = os.getenv('DOC_TEXT_COLUMN')  # Read from environment variable\n",
    "            filtered_df = output_df[[doc_text_column, hap_score_column]]\n",
    "\n",
    "            # Print the filtered DataFrame (only showing the HAP score and document text)\n",
    "            print(f\"Filtered Output (only HAP score and document text):\")\n",
    "            display(filtered_df)\n",
    "\n",
    "            # Save the complete output as a CSV file\n",
    "            output_df.to_csv(complete_output_csv, index=False)  # Convert the Parquet to CSV\n",
    "            print(f\"Complete output saved to: {complete_output_csv}\")\n",
    "\n",
    "            # Save the filtered output as a CSV file\n",
    "            filtered_df.to_csv(filtered_output_csv, index=False)\n",
    "            print(f\"Filtered output saved to: {filtered_output_csv}\")\n",
    "\n",
    "else:\n",
    "    print(\"No output files found. Please check the script or configuration.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataprepkit",
   "language": "python",
   "name": "data-prep-kit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
